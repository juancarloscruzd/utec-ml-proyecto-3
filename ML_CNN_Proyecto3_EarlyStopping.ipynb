{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "id": "EnOy-forKQjN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cu102/torch_stable.html\n",
      "Collecting torch==1.10.0+cu102"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 171, in _merge_into_criterion\n",
      "    crit = self.state.criteria[name]\n",
      "KeyError: 'torch'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 519, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\http\\client.py\", line 458, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\http\\client.py\", line 502, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 189, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 178, in wrapper"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading https://download.pytorch.org/whl/cu102/torch-1.10.0%2Bcu102-cp38-cp38-win_amd64.whl (1486.0 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 316, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 121, in resolve\n",
      "    self._result = resolver.resolve(\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 453, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 318, in resolve\n",
      "    name, crit = self._merge_into_criterion(r, parent=None)\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 173, in _merge_into_criterion\n",
      "    crit = Criterion.from_requirement(self._p, requirement, parent)\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 82, in from_requirement\n",
      "    if not cands:\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 124, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 143, in __bool__\n",
      "    return any(self)\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 38, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 167, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 300, in __init__\n",
      "    super().__init__(\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 144, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 226, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 311, in _prepare_distribution\n",
      "    return self._factory.preparer.prepare_linked_requirement(\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 457, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 480, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 230, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 108, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 163, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 159, in iter\n",
      "    for x in it:\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 64, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 576, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 541, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\contextlib.py\", line 131, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"C:\\Users\\coyol\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 455, in _error_catcher\n",
      "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
      "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)\", ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.10.0+cu102 torchvision==0.11.1+cu102 torchaudio===0.10.0+cu102 -f https://download.pytorch.org/whl/cu102/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\coyol\\anaconda3\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\coyol\\anaconda3\\lib\\site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\coyol\\anaconda3\\lib\\site-packages (0.11.1)\n",
      "Requirement already satisfied: torch==1.10.0 in c:\\users\\coyol\\anaconda3\\lib\\site-packages (from torchvision) (1.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\coyol\\anaconda3\\lib\\site-packages (from torchvision) (1.20.3)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\coyol\\anaconda3\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\coyol\\anaconda3\\lib\\site-packages (from torch==1.10.0->torchvision) (3.10.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "T4R8vmSCXfNn"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import math\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCaHPHrZzmBF",
    "outputId": "51aef535-ec76-4ebf-d9f4-3cf5bdeed6e9"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W27oYXNvzdC1",
    "outputId": "711afa28-3299-4b8a-e8f7-f07ea18ee0ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "14818\n",
      "4232\n",
      "2115\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32 #64\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "path = 'C:/Users/coyol/Desktop/utec/ciclo2/AI/Proyecto3/'\n",
    "#path = '/content/drive/Shareddrives/MachineLearning/CovidData/'\n",
    "\n",
    "train_set = torchvision.datasets.ImageFolder(root=path+'train', transform = transforms.ToTensor())\n",
    "val_set = torchvision.datasets.ImageFolder(root=path+'valid', transform = transforms.ToTensor())\n",
    "test_set = torchvision.datasets.ImageFolder(root=path+'test', transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(val_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PgF_3RNgTOJP"
   },
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "learning_rate =  0.001\n",
    "num_epochs = 20\n",
    "\n",
    "class CNN3(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(CNN3, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=2), #(299+2*2-3)/1+1 = 301\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)) #301/2=150.5 = 150\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2), #(150+2*2-5)/1+1 = 150\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)) #150/2 = 75\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2), #(75+2*2-5)/1+1 = 75\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)) #75/2 = 37\n",
    "        self.fc = nn.Linear(37*37*64, num_classes) #Aplica una transformación lineal: y=xA.T + b\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NxgKAJ40hd8J",
    "outputId": "a7e34b25-1032-4bab-b36a-2069f52bc3d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([4, 87616]), torch.Size([4])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0018,  0.0032, -0.0008,  ...,  0.0021,  0.0009,  0.0015],\n",
       "        [ 0.0005, -0.0012,  0.0012,  ..., -0.0021,  0.0012, -0.0026],\n",
       "        [ 0.0022, -0.0029,  0.0011,  ..., -0.0008,  0.0018, -0.0022],\n",
       "        [ 0.0032,  0.0005, -0.0032,  ..., -0.0007,  0.0020, -0.0026]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model         = CNN3(num_classes).to(device)\n",
    "loss_fn       = nn.CrossEntropyLoss()\n",
    "optimizer     = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "print([ e.shape  for e in model.fc.parameters()])\n",
    "\n",
    "model.fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "D3P8tMnHg4qj"
   },
   "outputs": [],
   "source": [
    "def checkStop(model, device, val_loader, loss_fn):\n",
    "    # Settings\n",
    "    model.eval()\n",
    "    perdida = 0\n",
    "\n",
    "    # Test validation data\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(val_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            perdida += loss.item()\n",
    "\n",
    "    return perdida / len(val_loader)\n",
    "\n",
    "def train(model, optimizer, loss_fn, num_epochs,train_loader,val_loader, numChecks):\n",
    "  #loss_vals = []\n",
    "  ultimoError = 10000\n",
    "\n",
    "  # train the model\n",
    "  total_step = len(train_loader)  # el train loader es el motor que se encarga de sacar las imagenes del train_set\n",
    "\n",
    "  list_loss= []\n",
    "  list_time = []\n",
    "  #list_loss_val = []\n",
    "  \n",
    "  j=0\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    k=0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "    #for i in range(50):\n",
    "\n",
    "      #images = train_loader[i][0].to(device)\n",
    "      #labels = train_loader[i][1].to(device)\n",
    "\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      \n",
    "      # forward \n",
    "      output = model(images)\n",
    "      loss   = loss_fn(output, labels)\n",
    "\n",
    "      # change the params\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      list_loss.append(loss.item())\n",
    "      list_time.append(j)\n",
    "      j+=1\n",
    "\n",
    "              \n",
    "      if (i+1) % 100 == 0:\n",
    "              print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                    .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "      k+=1\n",
    "      #if (k == 1000):\n",
    "      #  break \n",
    "\n",
    "    # Se ejecuta despues de cada epoch\n",
    "    # Se analiza el error sobre el conjunto de validacion - Eartly stopping\n",
    "    validError = checkStop(model, device, val_loader, loss_fn)\n",
    "    print('Error validacion:', validError)\n",
    "\n",
    "    if validError > ultimoError:\n",
    "        counter += 1\n",
    "        # En caso no se mejore en n veces el error, se detiene el algoritmo\n",
    "        if counter >= numChecks:\n",
    "            return list_loss\n",
    "    else:\n",
    "        # Se vuelve a contar\n",
    "        counter = 0\n",
    "\n",
    "        # error actual es menor que el ultimo error\n",
    "        ultimoError = validError\n",
    "    #print(\"LastError: \",ultimoError)\n",
    "  print('Finished Training Trainset')\n",
    "  return list_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "SZdOzO0NuR4f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [100/464], Loss: 8.4278\n",
      "Epoch [1/20], Step [200/464], Loss: 4.8450\n",
      "Epoch [1/20], Step [300/464], Loss: 6.4378\n",
      "Epoch [1/20], Step [400/464], Loss: 2.3327\n",
      "Error validacion: 2.1165688656326522\n",
      "Epoch [2/20], Step [100/464], Loss: 0.7712\n",
      "Epoch [2/20], Step [200/464], Loss: 0.7496\n",
      "Epoch [2/20], Step [300/464], Loss: 0.5754\n",
      "Epoch [2/20], Step [400/464], Loss: 0.5644\n",
      "Error validacion: 0.5952580096130085\n",
      "Epoch [3/20], Step [100/464], Loss: 0.6474\n",
      "Epoch [3/20], Step [200/464], Loss: 0.5411\n",
      "Epoch [3/20], Step [300/464], Loss: 0.6453\n",
      "Epoch [3/20], Step [400/464], Loss: 0.3876\n",
      "Error validacion: 0.6374189466013944\n",
      "Epoch [4/20], Step [100/464], Loss: 0.6897\n",
      "Epoch [4/20], Step [200/464], Loss: 0.5406\n",
      "Epoch [4/20], Step [300/464], Loss: 0.6501\n",
      "Epoch [4/20], Step [400/464], Loss: 0.5481\n",
      "Error validacion: 0.5285625870066478\n",
      "Epoch [5/20], Step [100/464], Loss: 0.6588\n",
      "Epoch [5/20], Step [200/464], Loss: 0.5519\n",
      "Epoch [5/20], Step [300/464], Loss: 0.3208\n",
      "Epoch [5/20], Step [400/464], Loss: 0.4238\n",
      "Error validacion: 0.547730404519497\n",
      "Epoch [6/20], Step [100/464], Loss: 0.3481\n",
      "Epoch [6/20], Step [200/464], Loss: 0.3447\n",
      "Epoch [6/20], Step [300/464], Loss: 0.7061\n",
      "Epoch [6/20], Step [400/464], Loss: 0.2625\n",
      "Error validacion: 0.5163565973254075\n",
      "Epoch [7/20], Step [100/464], Loss: 0.3922\n",
      "Epoch [7/20], Step [200/464], Loss: 0.4365\n",
      "Epoch [7/20], Step [300/464], Loss: 0.2497\n",
      "Epoch [7/20], Step [400/464], Loss: 0.4437\n",
      "Error validacion: 0.42955628687277775\n",
      "Epoch [8/20], Step [100/464], Loss: 0.2874\n",
      "Epoch [8/20], Step [200/464], Loss: 0.5574\n",
      "Epoch [8/20], Step [300/464], Loss: 0.2515\n",
      "Epoch [8/20], Step [400/464], Loss: 0.3138\n",
      "Error validacion: 0.415751354138654\n",
      "Epoch [9/20], Step [100/464], Loss: 0.3340\n",
      "Epoch [9/20], Step [200/464], Loss: 0.4391\n",
      "Epoch [9/20], Step [300/464], Loss: 0.2734\n",
      "Epoch [9/20], Step [400/464], Loss: 0.1525\n",
      "Error validacion: 0.4091187725053694\n",
      "Epoch [10/20], Step [100/464], Loss: 0.1263\n",
      "Epoch [10/20], Step [200/464], Loss: 0.3914\n",
      "Epoch [10/20], Step [300/464], Loss: 0.2655\n",
      "Epoch [10/20], Step [400/464], Loss: 0.3098\n",
      "Error validacion: 0.39753531558173044\n",
      "Epoch [11/20], Step [100/464], Loss: 0.2926\n",
      "Epoch [11/20], Step [200/464], Loss: 0.2405\n",
      "Epoch [11/20], Step [300/464], Loss: 0.2994\n",
      "Epoch [11/20], Step [400/464], Loss: 0.1994\n",
      "Error validacion: 0.35068480754481224\n",
      "Epoch [12/20], Step [100/464], Loss: 0.2214\n",
      "Epoch [12/20], Step [200/464], Loss: 0.2739\n",
      "Epoch [12/20], Step [300/464], Loss: 0.2195\n",
      "Epoch [12/20], Step [400/464], Loss: 0.1388\n",
      "Error validacion: 0.454498558340216\n",
      "Epoch [13/20], Step [100/464], Loss: 0.2177\n",
      "Epoch [13/20], Step [200/464], Loss: 0.0811\n",
      "Epoch [13/20], Step [300/464], Loss: 0.1520\n",
      "Epoch [13/20], Step [400/464], Loss: 0.2993\n",
      "Error validacion: 0.4207223935851029\n"
     ]
    }
   ],
   "source": [
    "numChecks = 2\n",
    "train_loss = train(model,optimizer,loss_fn,num_epochs,train_loader,val_loader,numChecks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "UIgfkY1iLk8C",
    "outputId": "389ccaf4-658f-4451-f0a3-686d5dc18a3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training Error: Early stopping')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.title(\"Training Error: Early stopping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpsjztIY2DSj",
    "outputId": "27154c4e-904f-4214-87fa-b10092ae3da7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy of the model: 85.89319470699432 %\n"
     ]
    }
   ],
   "source": [
    "#Precision con el set de validación (20%).\n",
    "with torch.no_grad():\n",
    "      correct = 0\n",
    "      total = 0\n",
    "      k=0\n",
    "      for images, labels in val_loader:\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "          outputs = model(images)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "          #k+=1\n",
    "          #if (k == 100):\n",
    "          #  break\n",
    "      print('Validation Accuracy of the model: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0WmRgNcWKQjb",
    "outputId": "0c699188-0c7a-43f7-ee84-4732a311ae2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model: 85.48463356973996 %\n"
     ]
    }
   ],
   "source": [
    "#Precision con el set de test (10%).\n",
    "with torch.no_grad():\n",
    "      correct = 0\n",
    "      total = 0\n",
    "      k=0\n",
    "      for images, labels in test_loader:\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "          outputs = model(images)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "          #k+=1\n",
    "          #if (k == 100):\n",
    "          #  break\n",
    "      print('Test Accuracy of the model: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wuguPd-KQjb"
   },
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ML_CNN_Proyecto3_Full_Dropout.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
